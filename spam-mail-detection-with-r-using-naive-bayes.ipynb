{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1c26c2",
   "metadata": {
    "papermill": {
     "duration": 0.009335,
     "end_time": "2022-09-21T18:05:26.751315",
     "exception": false,
     "start_time": "2022-09-21T18:05:26.741980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code below is based on the book \"Machine Learning for Hackers\", by Drew Conway and John Myles White.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4ff47",
   "metadata": {
    "papermill": {
     "duration": 0.005671,
     "end_time": "2022-09-21T18:05:26.762818",
     "exception": false,
     "start_time": "2022-09-21T18:05:26.757147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Packages\n",
    "\n",
    "We start by loading the libraries we'll need : \n",
    "* `tm` for text mining\n",
    "* `ggplot2`, to plot the results of my algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bedddf0d",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "051d70d956493feee0c6d64651c6a088724dca2a",
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:26.777911Z",
     "iopub.status.busy": "2022-09-21T18:05:26.775795Z",
     "iopub.status.idle": "2022-09-21T18:05:27.372941Z",
     "shell.execute_reply": "2022-09-21T18:05:27.370569Z"
    },
    "papermill": {
     "duration": 0.608446,
     "end_time": "2022-09-21T18:05:27.376717",
     "exception": false,
     "start_time": "2022-09-21T18:05:26.768271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: NLP\n",
      "\n",
      "\n",
      "Attaching package: ‘NLP’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:httr’:\n",
      "\n",
      "    content\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘ggplot2’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:NLP’:\n",
      "\n",
      "    annotate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tm)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50b082",
   "metadata": {
    "papermill": {
     "duration": 0.006633,
     "end_time": "2022-09-21T18:05:27.389526",
     "exception": false,
     "start_time": "2022-09-21T18:05:27.382893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing and Manipulating Data\n",
    "\n",
    "The spam and ham emails are split into two folders. Here, we save the paths to these folders in the objects `spam.path` and `ham.path`. Then, we use the `dir` function to create a vector with all of the names of the files within these directories. We call these vectors `spam.docs` and `ham.docs`.\n",
    "\n",
    "We removed the first spam mail from `spam.docs` because it didn't conform to the email format and this caused errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716fa387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:27.496713Z",
     "iopub.status.busy": "2022-09-21T18:05:27.404431Z",
     "iopub.status.idle": "2022-09-21T18:05:27.831315Z",
     "shell.execute_reply": "2022-09-21T18:05:27.829124Z"
    },
    "papermill": {
     "duration": 0.438063,
     "end_time": "2022-09-21T18:05:27.834357",
     "exception": false,
     "start_time": "2022-09-21T18:05:27.396294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spam.path <- '../input/ham-and-spam-dataset/spam'\n",
    "ham.path <- '../input/ham-and-spam-dataset/ham'\n",
    "\n",
    "spam.docs <- dir(spam.path)\n",
    "ham.docs <- dir(ham.path)\n",
    "\n",
    "spam.docs <- spam.docs[seq(2,length(spam.docs),1)] # remove first spam email, which is not in email format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2bea4",
   "metadata": {
    "papermill": {
     "duration": 0.00682,
     "end_time": "2022-09-21T18:05:27.847101",
     "exception": false,
     "start_time": "2022-09-21T18:05:27.840281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we create a function calld `get.msg`. `get.msg` opens a file and returns the e-mail message.\n",
    "\n",
    "We open the file in rt (read text) mode and used latin1 encoding, which supports non-ASCII characters, present in many emails.\n",
    "\n",
    "Then, we select the email text, which begins after the first line break. The text before that space is e-mail metadata, such as the email sender, receiver and the time the email was sent. Metadata can also be used for spam prediction, but we will not use it here.\n",
    "\n",
    "Finally, we use the `sample` function to split the ham and spam datasets into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "126bd9a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:27.863157Z",
     "iopub.status.busy": "2022-09-21T18:05:27.861300Z",
     "iopub.status.idle": "2022-09-21T18:05:52.291190Z",
     "shell.execute_reply": "2022-09-21T18:05:52.289204Z"
    },
    "papermill": {
     "duration": 24.441957,
     "end_time": "2022-09-21T18:05:52.295083",
     "exception": false,
     "start_time": "2022-09-21T18:05:27.853126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get.msg <- function(path){\n",
    "    con <- file(path, open = 'rt', encoding = 'latin1') # open file connection\n",
    "    text <- readLines(con) # read file content\n",
    "    msg <- text[seq(which(text==\"\")[1]+1,length(text),1)] # get text that begins after first line break\n",
    "    close(con) # clone connection\n",
    "    return(paste(msg, collapse = '\\n'))  # return email message\n",
    "}\n",
    "\n",
    "all.spam <- sapply(spam.docs, function(p) get.msg(file.path(spam.path, p)))\n",
    "all.ham <- sapply(ham.docs, function(p) get.msg(file.path(ham.path, p)))\n",
    "                  \n",
    "spam.train <- sample(all.spam, floor(0.7*length(all.spam)), replace = FALSE)\n",
    "spam.test <- setdiff(all.spam, spam.train)\n",
    "\n",
    "ham.train <- sample(all.ham, floor(0.7*length(all.ham)), replace = FALSE)\n",
    "ham.test <- setdiff(all.ham, ham.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a89fb1",
   "metadata": {
    "papermill": {
     "duration": 0.00608,
     "end_time": "2022-09-21T18:05:52.308326",
     "exception": false,
     "start_time": "2022-09-21T18:05:52.302246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bulding a Term-Document Matrix\n",
    "\n",
    "Now that we've extracted the email message from all email files, we will create a function to generate a Term-Document Matrix, or TDM. A TDM is an $N \\times M$ matrix in which the $N$ terms found in the documents are represented in the rows and the $M$ documents are represented in the columns. The $[i,j]$ cell of this matrix corresponds to how many times the term $i$ was found in document $j$.\n",
    "\n",
    "The `TermDocumentMatrix` function from the tm library requires two parameters : a document corpus parameter, which is a collection of documents, and a control parameter, which specifies which settings to use when building the TDM.\n",
    "\n",
    "You can build a corups in several ways. Here, because we are using a vector of spam mails as a source, we used the `VectorSource` function into the `Corpus` function. If you want to know more about sources for bulding a corpus, enter `?getSources` at the R console.\n",
    "\n",
    "For contol, we used `stopwords = TRUE`, which removes common English [stop words](https://en.wikipedia.org/wiki/Stop_word) from the TDM. You can enter `stopwords()` at the R console to see which are these words. We also set `removePunctiation = TRUE` and `removeNumbers = TRUE`, which are self-explanatory. Finally, we set `minDocFrequency = 2`, which assures only terms appearing more than once will show up in the TDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03489d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:52.323646Z",
     "iopub.status.busy": "2022-09-21T18:05:52.322067Z",
     "iopub.status.idle": "2022-09-21T18:05:52.338251Z",
     "shell.execute_reply": "2022-09-21T18:05:52.336372Z"
    },
    "papermill": {
     "duration": 0.027379,
     "end_time": "2022-09-21T18:05:52.341630",
     "exception": false,
     "start_time": "2022-09-21T18:05:52.314251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "get.tdm <- function(doc.vec){\n",
    "    doc.corpus <- Corpus(VectorSource(doc.vec))\n",
    "    control <- list(stopwords = TRUE, removePunctuation = TRUE, removeNumbers = TRUE,\n",
    "                   minDocFreq = 2)\n",
    "    doc.dtm <- TermDocumentMatrix(doc.corpus, control)\n",
    "    return(doc.dtm)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2969d316",
   "metadata": {
    "papermill": {
     "duration": 0.006073,
     "end_time": "2022-09-21T18:05:52.353850",
     "exception": false,
     "start_time": "2022-09-21T18:05:52.347777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we've created the TDM, we will build a data frame that contains the probability of each term showing up in an email, given that we know its a spam mail. We will use this information to calculate the probability of an email being spam, given that a given set of terms showed up in it.\n",
    "\n",
    "We also calculate the term density, that is, the proportion of a specific term within the whole set of terms observed. We will not use the frequency information for classification, but it will be useful to see how these numbers compare when we consider how certain words might be affecting our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44f38db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:52.369451Z",
     "iopub.status.busy": "2022-09-21T18:05:52.367714Z",
     "iopub.status.idle": "2022-09-21T18:05:53.708760Z",
     "shell.execute_reply": "2022-09-21T18:05:53.706699Z"
    },
    "papermill": {
     "duration": 1.351741,
     "end_time": "2022-09-21T18:05:53.711558",
     "exception": false,
     "start_time": "2022-09-21T18:05:52.359817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spam.tdm <- get.tdm(spam.train) # TDM = Term Document Matrix. Term (x axis) vs Document (y axis)\n",
    "\n",
    "spam.matrix <- as.matrix(spam.tdm)\n",
    "spam.counts <- rowSums(spam.matrix) # vector that contains term frequency counts\n",
    "spam.df <- data.frame(names(spam.counts),\n",
    "                     as.numeric(spam.counts),\n",
    "                     stringAsFactors = FALSE)\n",
    "\n",
    "names(spam.df) <- c('term', 'frequency')\n",
    "\n",
    "spam.occurrence <- sapply(1:nrow(spam.matrix), \n",
    " function(i) {length(which(spam.matrix[i,] > 0))/ncol(spam.matrix)}) # prop. of word occurence in documents\n",
    "\n",
    "spam.density <- spam.df$frequency/sum(spam.df$frequency) # prop. of word occurence in words\n",
    "\n",
    "spam.df <- transform(spam.df, density = spam.density, occurrence = spam.occurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdf9d7",
   "metadata": {
    "papermill": {
     "duration": 0.015059,
     "end_time": "2022-09-21T18:05:53.732651",
     "exception": false,
     "start_time": "2022-09-21T18:05:53.717592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We investigate which terms are more strongly associated with spam mail by ordering the top 10 terms according to the term occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa84001b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:53.748427Z",
     "iopub.status.busy": "2022-09-21T18:05:53.746864Z",
     "iopub.status.idle": "2022-09-21T18:05:53.784223Z",
     "shell.execute_reply": "2022-09-21T18:05:53.782406Z"
    },
    "papermill": {
     "duration": 0.04783,
     "end_time": "2022-09-21T18:05:53.786678",
     "exception": false,
     "start_time": "2022-09-21T18:05:53.738848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>term</th><th scope=col>frequency</th><th scope=col>NA.</th><th scope=col>density</th><th scope=col>occurrence</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>11</th><td>email </td><td>582</td><td>FALSE</td><td>0.006427459</td><td>0.5600000</td></tr>\n",
       "\t<tr><th scope=row>50</th><td>please</td><td>304</td><td>FALSE</td><td>0.003357298</td><td>0.5257143</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>list  </td><td>302</td><td>FALSE</td><td>0.003335211</td><td>0.4628571</td></tr>\n",
       "\t<tr><th scope=row>140</th><td>will  </td><td>568</td><td>FALSE</td><td>0.006272847</td><td>0.4228571</td></tr>\n",
       "\t<tr><th scope=row>392</th><td>body  </td><td>266</td><td>FALSE</td><td>0.002937636</td><td>0.4142857</td></tr>\n",
       "\t<tr><th scope=row>476</th><td>free  </td><td>381</td><td>FALSE</td><td>0.004207667</td><td>0.3971429</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & term & frequency & NA. & density & occurrence\\\\\n",
       "  & <chr> & <dbl> & <lgl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t11 & email  & 582 & FALSE & 0.006427459 & 0.5600000\\\\\n",
       "\t50 & please & 304 & FALSE & 0.003357298 & 0.5257143\\\\\n",
       "\t33 & list   & 302 & FALSE & 0.003335211 & 0.4628571\\\\\n",
       "\t140 & will   & 568 & FALSE & 0.006272847 & 0.4228571\\\\\n",
       "\t392 & body   & 266 & FALSE & 0.002937636 & 0.4142857\\\\\n",
       "\t476 & free   & 381 & FALSE & 0.004207667 & 0.3971429\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | term &lt;chr&gt; | frequency &lt;dbl&gt; | NA. &lt;lgl&gt; | density &lt;dbl&gt; | occurrence &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 11 | email  | 582 | FALSE | 0.006427459 | 0.5600000 |\n",
       "| 50 | please | 304 | FALSE | 0.003357298 | 0.5257143 |\n",
       "| 33 | list   | 302 | FALSE | 0.003335211 | 0.4628571 |\n",
       "| 140 | will   | 568 | FALSE | 0.006272847 | 0.4228571 |\n",
       "| 392 | body   | 266 | FALSE | 0.002937636 | 0.4142857 |\n",
       "| 476 | free   | 381 | FALSE | 0.004207667 | 0.3971429 |\n",
       "\n"
      ],
      "text/plain": [
       "    term   frequency NA.   density     occurrence\n",
       "11  email  582       FALSE 0.006427459 0.5600000 \n",
       "50  please 304       FALSE 0.003357298 0.5257143 \n",
       "33  list   302       FALSE 0.003335211 0.4628571 \n",
       "140 will   568       FALSE 0.006272847 0.4228571 \n",
       "392 body   266       FALSE 0.002937636 0.4142857 \n",
       "476 free   381       FALSE 0.004207667 0.3971429 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(spam.df[with(spam.df, order(-occurrence)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703b1ce",
   "metadata": {
    "papermill": {
     "duration": 0.006677,
     "end_time": "2022-09-21T18:05:53.799910",
     "exception": false,
     "start_time": "2022-09-21T18:05:53.793233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we repeat the same process for ham mail and investigate which terms are more strongly associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9ecbdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:53.816125Z",
     "iopub.status.busy": "2022-09-21T18:05:53.814410Z",
     "iopub.status.idle": "2022-09-21T18:05:58.584269Z",
     "shell.execute_reply": "2022-09-21T18:05:58.582417Z"
    },
    "papermill": {
     "duration": 4.780789,
     "end_time": "2022-09-21T18:05:58.587052",
     "exception": false,
     "start_time": "2022-09-21T18:05:53.806263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ham.tdm <- get.tdm(ham.train) # TDM = Term Document Matrix. Term (x axis) vs Document (y axis)\n",
    "\n",
    "ham.matrix <- as.matrix(ham.tdm)\n",
    "ham.counts <- rowSums(ham.matrix) # vector that contains term frequency counts\n",
    "ham.df <- data.frame(cbind(names(ham.counts)),\n",
    "                     as.numeric(ham.counts),\n",
    "                     stringAsFactors = FALSE)\n",
    "\n",
    "names(ham.df) <- c('term', 'frequency')\n",
    "\n",
    "ham.df$frequency <- as.numeric(ham.df$frequency) # unnecessary?\n",
    "\n",
    "ham.occurrence <- sapply(1:nrow(ham.matrix), \n",
    " function(i) {length(which(ham.matrix[i,] > 0))/ncol(ham.matrix)}) # prop. of word occurence in documents\n",
    "ham.density <- ham.df$frequency/sum(ham.df$frequency) # prop. of word occurence in words\n",
    "ham.df <- transform(ham.df, density = ham.density, occurrence = ham.occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706f282b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:58.603194Z",
     "iopub.status.busy": "2022-09-21T18:05:58.601555Z",
     "iopub.status.idle": "2022-09-21T18:05:58.634678Z",
     "shell.execute_reply": "2022-09-21T18:05:58.632791Z"
    },
    "papermill": {
     "duration": 0.044021,
     "end_time": "2022-09-21T18:05:58.637309",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.593288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>term</th><th scope=col>frequency</th><th scope=col>NA.</th><th scope=col>density</th><th scope=col>occurrence</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>35</th><td>list   </td><td> 944</td><td>FALSE</td><td>0.004701991</td><td>0.3843137</td></tr>\n",
       "\t<tr><th scope=row>245</th><td>date   </td><td> 618</td><td>FALSE</td><td>0.003078210</td><td>0.3238095</td></tr>\n",
       "\t<tr><th scope=row>1084</th><td>mailing</td><td> 618</td><td>FALSE</td><td>0.003078210</td><td>0.3092437</td></tr>\n",
       "\t<tr><th scope=row>162</th><td>can    </td><td>1037</td><td>FALSE</td><td>0.005165217</td><td>0.3086835</td></tr>\n",
       "\t<tr><th scope=row>58</th><td>wrote  </td><td> 646</td><td>FALSE</td><td>0.003217676</td><td>0.3030812</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>just   </td><td> 872</td><td>FALSE</td><td>0.004343365</td><td>0.2969188</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & term & frequency & NA. & density & occurrence\\\\\n",
       "  & <chr> & <dbl> & <lgl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t35 & list    &  944 & FALSE & 0.004701991 & 0.3843137\\\\\n",
       "\t245 & date    &  618 & FALSE & 0.003078210 & 0.3238095\\\\\n",
       "\t1084 & mailing &  618 & FALSE & 0.003078210 & 0.3092437\\\\\n",
       "\t162 & can     & 1037 & FALSE & 0.005165217 & 0.3086835\\\\\n",
       "\t58 & wrote   &  646 & FALSE & 0.003217676 & 0.3030812\\\\\n",
       "\t33 & just    &  872 & FALSE & 0.004343365 & 0.2969188\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | term &lt;chr&gt; | frequency &lt;dbl&gt; | NA. &lt;lgl&gt; | density &lt;dbl&gt; | occurrence &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 35 | list    |  944 | FALSE | 0.004701991 | 0.3843137 |\n",
       "| 245 | date    |  618 | FALSE | 0.003078210 | 0.3238095 |\n",
       "| 1084 | mailing |  618 | FALSE | 0.003078210 | 0.3092437 |\n",
       "| 162 | can     | 1037 | FALSE | 0.005165217 | 0.3086835 |\n",
       "| 58 | wrote   |  646 | FALSE | 0.003217676 | 0.3030812 |\n",
       "| 33 | just    |  872 | FALSE | 0.004343365 | 0.2969188 |\n",
       "\n"
      ],
      "text/plain": [
       "     term    frequency NA.   density     occurrence\n",
       "35   list     944      FALSE 0.004701991 0.3843137 \n",
       "245  date     618      FALSE 0.003078210 0.3238095 \n",
       "1084 mailing  618      FALSE 0.003078210 0.3092437 \n",
       "162  can     1037      FALSE 0.005165217 0.3086835 \n",
       "58   wrote    646      FALSE 0.003217676 0.3030812 \n",
       "33   just     872      FALSE 0.004343365 0.2969188 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(ham.df[with(ham.df, order(-occurrence)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bd44c",
   "metadata": {
    "papermill": {
     "duration": 0.006362,
     "end_time": "2022-09-21T18:05:58.650337",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.643975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building the Classifier\n",
    "\n",
    "Finally, we build a classifier. We use the occurrence data to calculate the conditional probability of an email being spam or ham given the observed words in the email. We do this using Bayes' Theorem: \n",
    "\n",
    "\\begin{equation}\n",
    "P(spam|words) = \\frac{P(words|spam)P(spam)}{P(words)}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(ham|words) = \\frac{P(words|ham)P(ham)}{P(words)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Since we are only interested in the conditional probability of an email being spam in comparison to it being ham, not in its absolute value, we discard the $P(data)$ in the denominator, which is called the marginal likelihood, and use the proportional probability instead:\n",
    "\n",
    "\\begin{equation}\n",
    "P(spam|words) \\propto P(words|spam)P(spam)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(ham|words) \\propto P(words|ham)P(ham)\n",
    "\\end{equation}\n",
    "\n",
    "For now, we assume $P(spam)=P(ham)=0.5$. Because we make this assumption without being certain that it is correct, we call this model Naive Bayes.\n",
    "\n",
    "According to Conway and White :\n",
    "\n",
    "\"To calculate the conditional probability of a message, we combine the probabilities of\n",
    "each term in the training data by taking their product. For example, if the frequency of\n",
    "seeing html in a spam message is 0.30 and the frequency of seeing table in a spam\n",
    "message is 0.10, then we’ll say that the probability of seeing both in a spam message is\n",
    "0.30 × 0.10 = 0.03. But for those terms in the email that are not in our training data,\n",
    "we have no information about their frequency in either spam or ham messages. \n",
    "\n",
    "One possible solution would be to assume that because we have not seen a term yet, its\n",
    "probability of occurring in a certain class is zero. This, however, is very misguided.\n",
    "First, it is foolish to assume that we will never see a term in the entire universe of spam\n",
    "and ham simply because we have not yet seen it. Moreover, because we calculate conditional probabilities using products, if we assigned a zero probability to terms not in\n",
    "our training data, elementary arithmetic tells us that we would calculate zero as the\n",
    "probability of most messages, because we would be multiplying all the other probabilities by zero every time we encountered an unknown term. This would cause\n",
    "catastrophic results for our classifier because many, or even all, messages would be\n",
    "incorrectly assigned a zero probability of being either spam or ham.\n",
    "\n",
    "Researchers have come up with many clever ways of trying to get around this problem,\n",
    "such as drawing a random probability from some distribution or using natural language\n",
    "processing (NLP) techniques to estimate the “spamminess” of a term given its context.\n",
    "For our purposes, we will use a very simple rule: assign a very small probability to terms\n",
    "that are not in the training set. This is, in fact, a common way of dealing with missing\n",
    "terms in simple text classifiers\"\n",
    "\n",
    "Conway and White set this small probability to $0.0001\\%$ for the use case in their book \"Machine Learning for Hackers\". However, this probability might be too large or too small in other cases. Here, we use $0.01\\%$, because we discovered through trial and error that this probability yields better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f67261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:58.667287Z",
     "iopub.status.busy": "2022-09-21T18:05:58.665639Z",
     "iopub.status.idle": "2022-09-21T18:05:58.682226Z",
     "shell.execute_reply": "2022-09-21T18:05:58.680392Z"
    },
    "papermill": {
     "duration": 0.028149,
     "end_time": "2022-09-21T18:05:58.684732",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.656583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classify.email <- function(msg, training.df, prior=0.5, c= 1e-4) {\n",
    " msg.tdm <- get.tdm(msg) # get the email message\n",
    " msg.freq <- rowSums(as.matrix(msg.tdm)) # calculate term frequency\n",
    " # Find intersections of words between TDM and message\n",
    " msg.match <- intersect(names(msg.freq), training.df$term)  \n",
    " if(length(msg.match) < 1) {\n",
    " return(prior*c^(length(msg.freq)))\n",
    " }\n",
    " else {\n",
    " match.probs <- training.df$occurrence[match(msg.match, training.df$term)]\n",
    " return(prior * prod(match.probs) * c^(length(msg.freq)-length(msg.match)))\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec68345",
   "metadata": {
    "papermill": {
     "duration": 0.006728,
     "end_time": "2022-09-21T18:05:58.698361",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.691633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `spam.classifier` function calculates the proportional probability of an email being spam or ham for each email and returns 1 if it is classified as spam and 0 if it is classified as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d3308ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:58.714914Z",
     "iopub.status.busy": "2022-09-21T18:05:58.713105Z",
     "iopub.status.idle": "2022-09-21T18:05:58.730769Z",
     "shell.execute_reply": "2022-09-21T18:05:58.728853Z"
    },
    "papermill": {
     "duration": 0.029233,
     "end_time": "2022-09-21T18:05:58.733936",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.704703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spam.classifier <- function(docVec) {\n",
    " pr.spam <- classify.email(docVec, spam.df) # calculate spam probability\n",
    " pr.ham <- classify.email(docVec, ham.df) # calculate ham probability\n",
    " return(ifelse(pr.spam > pr.ham, 1, 0))\n",
    "}\n",
    "# returns 1 if email is classified as spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfcc57",
   "metadata": {
    "papermill": {
     "duration": 0.006544,
     "end_time": "2022-09-21T18:05:58.747915",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.741371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We apply `spam.classifier` to test ham and test spam data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8038cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:05:58.764233Z",
     "iopub.status.busy": "2022-09-21T18:05:58.762566Z",
     "iopub.status.idle": "2022-09-21T18:06:12.536970Z",
     "shell.execute_reply": "2022-09-21T18:06:12.534909Z"
    },
    "papermill": {
     "duration": 13.785272,
     "end_time": "2022-09-21T18:06:12.539559",
     "exception": false,
     "start_time": "2022-09-21T18:05:58.754287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spamClassification <- sapply(spam.test, spam.classifier)\n",
    "hamClassification <- sapply(ham.test, spam.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e5963",
   "metadata": {
    "papermill": {
     "duration": 0.007215,
     "end_time": "2022-09-21T18:06:12.553518",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.546303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we create a data frame with classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2105f807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:06:12.570716Z",
     "iopub.status.busy": "2022-09-21T18:06:12.568500Z",
     "iopub.status.idle": "2022-09-21T18:06:12.599251Z",
     "shell.execute_reply": "2022-09-21T18:06:12.596822Z"
    },
    "papermill": {
     "duration": 0.042018,
     "end_time": "2022-09-21T18:06:12.602016",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.559998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>spam</th><th scope=col>ham</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Classified as ham</th><td>43</td><td>692</td></tr>\n",
       "\t<tr><th scope=row>Classified as spam</th><td>86</td><td>  5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & spam & ham\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tClassified as ham & 43 & 692\\\\\n",
       "\tClassified as spam & 86 &   5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 2\n",
       "\n",
       "| <!--/--> | spam &lt;dbl&gt; | ham &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| Classified as ham | 43 | 692 |\n",
       "| Classified as spam | 86 |   5 |\n",
       "\n"
      ],
      "text/plain": [
       "                   spam ham\n",
       "Classified as ham  43   692\n",
       "Classified as spam 86     5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classificationDf <- data.frame(\n",
    "spam = c(length(spamClassification) - sum(spamClassification), sum(spamClassification)),\n",
    "ham = c(length(hamClassification) - sum(hamClassification), sum(hamClassification))\n",
    ")\n",
    "\n",
    "row.names(classificationDf) <- c('Classified as ham', 'Classified as spam')\n",
    "\n",
    "classificationDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741d3d2",
   "metadata": {
    "papermill": {
     "duration": 0.007114,
     "end_time": "2022-09-21T18:06:12.616142",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.609028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we see the results in proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6328424f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-21T18:06:12.633339Z",
     "iopub.status.busy": "2022-09-21T18:06:12.631673Z",
     "iopub.status.idle": "2022-09-21T18:06:12.658495Z",
     "shell.execute_reply": "2022-09-21T18:06:12.656122Z"
    },
    "papermill": {
     "duration": 0.03892,
     "end_time": "2022-09-21T18:06:12.661805",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.622885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>spam</th><th scope=col>ham</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Classified as ham</th><td>0.3333333</td><td>0.992826399</td></tr>\n",
       "\t<tr><th scope=row>Classified as spam</th><td>0.6666667</td><td>0.007173601</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 2 of type dbl\n",
       "\\begin{tabular}{r|ll}\n",
       "  & spam & ham\\\\\n",
       "\\hline\n",
       "\tClassified as ham & 0.3333333 & 0.992826399\\\\\n",
       "\tClassified as spam & 0.6666667 & 0.007173601\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 2 of type dbl\n",
       "\n",
       "| <!--/--> | spam | ham |\n",
       "|---|---|---|\n",
       "| Classified as ham | 0.3333333 | 0.992826399 |\n",
       "| Classified as spam | 0.6666667 | 0.007173601 |\n",
       "\n"
      ],
      "text/plain": [
       "                   spam      ham        \n",
       "Classified as ham  0.3333333 0.992826399\n",
       "Classified as spam 0.6666667 0.007173601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prop.table(as.matrix(classificationDf),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df964d8",
   "metadata": {
    "papermill": {
     "duration": 0.006933,
     "end_time": "2022-09-21T18:06:12.675799",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.668866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our algorithm identified spam mail correctly in approximately $67\\%$ of cases. Ham mail was classified correctly in almost all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe1678",
   "metadata": {
    "papermill": {
     "duration": 0.00743,
     "end_time": "2022-09-21T18:06:12.689881",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.682451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32262001",
   "metadata": {
    "papermill": {
     "duration": 0.00688,
     "end_time": "2022-09-21T18:06:12.703943",
     "exception": false,
     "start_time": "2022-09-21T18:06:12.697063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are a few possible steps in which we could improve this algoritm. I will add them in following versions of this article.\n",
    "\n",
    "We can use bootstraping to find out the best value for `c`, the \"small probability\" mentioned above. \n",
    "\n",
    "We can also try using a non-naive Bayes algorithm, that is, an algoritm in which $P(spam) \\neq P(ham)$.\n",
    "\n",
    "We can also use external data to identify blacklisted sender emails or IP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.534628,
   "end_time": "2022-09-21T18:06:12.933047",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-21T18:05:22.398419",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
